{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(color_codes=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets (prototypes, fmnist, cifar10tl, imagenettetl, cifar100tl)\n",
    "dataset = \"fmnist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_all = pd.read_csv(f'out/{dataset}/our.csv')\n",
    "sgd_bin_m1_all = pd.read_csv(f'out/{dataset}/sgd_bin.csv')\n",
    "if dataset != \"prototypes\":\n",
    "    sgd_small_all = pd.read_csv(f'out/{dataset}/sgd.csv')\n",
    "baldassi_all = pd.read_csv(f'out/{dataset}/baldassi.csv')\n",
    "\n",
    "sgd_bin_m1_all['mean_val_acc'] = sgd_bin_m1_all['mean_val_acc']*100\n",
    "sgd_bin_m1_all['std_val_acc'] = sgd_bin_m1_all['std_val_acc']*100\n",
    "if dataset != \"prototypes\":\n",
    "    sgd_small_all['mean_val_acc'] = sgd_small_all['mean_val_acc']*100\n",
    "    sgd_small_all['std_val_acc'] = sgd_small_all['std_val_acc']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=100\n",
    "output_dim = 10\n",
    "\n",
    "if dataset == \"cifar10tl\":\n",
    "    input_dim = 9216\n",
    "    dataset_size = 40000\n",
    "elif dataset == \"cifar100tl\":\n",
    "    input_dim = 9216\n",
    "    dataset_size = 40000\n",
    "    output_dim = 100\n",
    "elif dataset == \"imagenettetl\":\n",
    "    input_dim = 2304\n",
    "    dataset_size = 10000\n",
    "elif dataset == \"prototypes\":\n",
    "    input_dim = 1000\n",
    "    dataset_size = 10000\n",
    "else:\n",
    "    input_dim = 784\n",
    "    dataset_size = 50000\n",
    "    \n",
    "# Compute memory requirements\n",
    "def compute_memory(layers, baldassi=False, adam=False):\n",
    "    mem_w, mem_w_ll, mem_w_gl, mem_h, mem_d = {}, {}, {}, {}, {}\n",
    "    mem_w[layers], mem_w_ll[layers], mem_w_gl[layers], mem_h[layers], mem_d[layers] = 0, 0, 0, 0, 0\n",
    "    layer_sizes = [int(x) for x in layers.split('_')]\n",
    "    prev_size = input_dim\n",
    "    mem_w_ll[layers], mem_d[layers] = 0, 0\n",
    "    for i, size in enumerate(layer_sizes):\n",
    "        if not baldassi or i%2 == 0:\n",
    "            # Weight dim\n",
    "            mem_w[layers] += prev_size * size\n",
    "        elif baldassi and i%2 == 1:\n",
    "            # Grouping layer weight dim\n",
    "            mem_w_gl[layers] += prev_size * size\n",
    "        \n",
    "        # Pre-activation dim\n",
    "        mem_h[layers] += size * bs\n",
    "        \n",
    "        # Locall loss weights dim\n",
    "        mem_w_ll[layers] = max(mem_w_ll[layers], size * output_dim)\n",
    "        \n",
    "        # Gradient dim\n",
    "        mem_d[layers] = max(mem_d[layers], prev_size * size)\n",
    "        \n",
    "        # Update previous size\n",
    "        prev_size = size\n",
    "    \n",
    "    # Output layer dim\n",
    "    mem_w[layers] += layer_sizes[-1] * output_dim\n",
    "    \n",
    "    # Output pre-activation dim\n",
    "    mem_h[layers] += output_dim * bs\n",
    "    \n",
    "    if adam:\n",
    "        mem_w[layers] *= 3\n",
    "        \n",
    "    return mem_w, mem_w_ll, mem_w_gl, mem_h, mem_d\n",
    "\n",
    "# Compute computational requirements\n",
    "def compute_operations(layers, binary=False, localloss=False, optimizer='sgd'):\n",
    "    layers_sizes = [int(x) for x in layers.split('_')]\n",
    "    layers_sizes = [input_dim] + layers_sizes + [output_dim]  # Add input and output layers\n",
    "    \n",
    "    if binary:\n",
    "        total_xnor, total_popcount, total_increment = 0, 0, 0\n",
    "    else:\n",
    "        total_mult, total_add = 0, 0\n",
    "    \n",
    "    for i in range(len(layers_sizes) - 1):\n",
    "        input_size, output_size = layers_sizes[i], layers_sizes[i + 1]\n",
    "        elems = input_size * output_size\n",
    "        \n",
    "        if binary:\n",
    "            forward_xnor = bs * elems\n",
    "            forward_popcount = bs * elems\n",
    "            local_classifier_xnor = bs * output_size * output_dim if localloss else 0\n",
    "            local_classifier_popcount = bs * output_dim * output_size if localloss else 0\n",
    "            \n",
    "            backward_xnor = 9 * bs * output_size if i != len(layers_sizes) - 2 else 0\n",
    "            weight_update_xnor = 2 * elems if i != len(layers_sizes) - 2 else 0\n",
    "            weight_update_popcount = elems if i != len(layers_sizes) - 2 else 0\n",
    "            weight_update_increment = 4 * elems if i != len(layers_sizes) - 2 else 0\n",
    "            \n",
    "            total_xnor += (forward_xnor + backward_xnor + weight_update_xnor + local_classifier_xnor)\n",
    "            total_popcount += (forward_popcount + weight_update_popcount + local_classifier_popcount)\n",
    "            total_increment += weight_update_increment\n",
    "        else:\n",
    "            forward_mult = bs * elems\n",
    "            forward_add = bs * (input_size - 1) * output_size\n",
    "            \n",
    "            backward_mult_weight = bs * elems\n",
    "            backward_add_weight = bs * (input_size - 1) * output_size\n",
    "            \n",
    "            backward_mult_input = bs * elems if i > 0 else 0\n",
    "            backward_add_input = bs * (output_size - 1) * input_size if i > 0 else 0            \n",
    "            \n",
    "            # --- weight update ---\n",
    "            if optimizer.lower() == 'sgd':\n",
    "                # classic SGD update: 1 mult + 1 add per weight\n",
    "                weight_update_mult = elems\n",
    "                weight_update_add  = elems\n",
    "                \n",
    "            elif optimizer.lower() == 'adam':\n",
    "                # 1) m_t = β1·m + (1-β1)·g : 2 mults, 1 add\n",
    "                # 2) v_t = β2·v + (1-β2)·g²: 3 mults (g²+two scales), 1 add\n",
    "                weight_update_mult = elems * (2 + 3)\n",
    "                weight_update_add  = elems * (1 + 1)\n",
    "                \n",
    "                # 3) bias‐correction & normalization:\n",
    "                #    m̂ = m_t/(1−β1^t), v̂ = v_t/(1−β2^t) → 2 divisions\n",
    "                #    sqrt(v̂) → 1 sqrt\n",
    "                #    sqrt(v̂)+ε → 1 add\n",
    "                #    m̂/(sqrt(v̂)+ε) → 1 division\n",
    "                weight_update_mult += elems * 4\n",
    "                weight_update_add  += elems  # sqrt+ε\n",
    "                \n",
    "                # 4) lr * … and subtract from w\n",
    "                weight_update_mult += elems     # lr * normalized m\n",
    "                weight_update_add  += elems     # w ← w − Δ\n",
    "            \n",
    "            total_mult += (forward_mult + backward_mult_weight + backward_mult_input + weight_update_mult)\n",
    "            total_add += (forward_add + backward_add_weight + backward_add_input + weight_update_add)\n",
    "            \n",
    "    if binary:\n",
    "        return total_xnor, total_popcount, total_increment\n",
    "    else:\n",
    "        return total_mult, total_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_sgd_small, mem_sgd_bin_m1, mem_ll, mem_baldassi, mem_bin_adam, mem_small_adam = {}, {}, {}, {}, {}, {}\n",
    "for i, row in our_all.iterrows():\n",
    "    mem_w, mem_w_ll, mem_w_gl, mem_h, mem_d = compute_memory(row['layers'])\n",
    "    mem_ll[row[\"layers\"]] = input_dim*dataset_size*1 + mem_w[row[\"layers\"]]*8 + mem_w_ll[row[\"layers\"]]*1 + mem_h[row[\"layers\"]]*8\n",
    "if dataset != \"prototypes\":\n",
    "    for i, row in sgd_small_all.iterrows():\n",
    "        mem_w, mem_w_ll, mem_w_gl, mem_h, mem_d = compute_memory(row['layers'])\n",
    "        mem_sgd_small[row[\"layers\"]] = input_dim*dataset_size//32*32 + mem_w[row[\"layers\"]]*32 + mem_h[row[\"layers\"]]*32 + mem_d[row[\"layers\"]]*32\n",
    "for i, row in sgd_bin_m1_all.iterrows():\n",
    "    mem_w, mem_w_ll, mem_w_gl, mem_h, mem_d = compute_memory(row['layers'])\n",
    "    mem_sgd_bin_m1[row[\"layers\"]] = input_dim*dataset_size*1 + mem_w[row[\"layers\"]]*32 + mem_h[row[\"layers\"]]*32 + mem_d[row[\"layers\"]]*32\n",
    "for i, row in baldassi_all.iterrows():\n",
    "    mem_w, mem_w_ll, mem_w_gl, mem_h, mem_d = compute_memory(row['layers'], baldassi=True)\n",
    "    mem_baldassi[row[\"layers\"]] = input_dim*dataset_size*1 + mem_w[row[\"layers\"]]*8 + mem_w_gl[row[\"layers\"]]*1 + mem_h[row[\"layers\"]]*8\n",
    "\n",
    "   \n",
    "our_all['memory'] = our_all['layers'].apply(lambda x: mem_ll[x])\n",
    "sgd_bin_m1_all['memory'] = sgd_bin_m1_all['layers'].apply(lambda x: mem_sgd_bin_m1[x])\n",
    "if dataset != \"prototypes\":\n",
    "    sgd_small_all['memory'] = sgd_small_all['layers'].apply(lambda x: mem_sgd_small[x])\n",
    "baldassi_all['memory'] = baldassi_all['layers'].apply(lambda x: mem_baldassi[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"imagenettetl\":\n",
    "    our_df = our_all[our_all[\"layers\"].isin([\"525_525\", \"255_255\", \"135_135\", \"75_75\", \"35_35\"])]\n",
    "    sgd_bin_m1_df = sgd_bin_m1_all[sgd_bin_m1_all[\"layers\"].isin([\"81_81\", \"36_36\", \"19_19\", \"10_10\", \"5_5\"])]\n",
    "    sgd_small_df = sgd_small_all[sgd_small_all[\"layers\"].isin([\"81_81\", \"36_36\", \"19_19\", \"10_10\", \"5_5\"])]\n",
    "    baldassi_df = baldassi_all[baldassi_all[\"layers\"].isin([\"660_60\", \"286_26\", \"154_14\", \"77_7\", \"44_4\"])]\n",
    "elif dataset == \"prototypes\":\n",
    "    our_df = our_all[our_all[\"layers\"].isin([\"525_525\", \"255_255\", \"135_135\", \"75_75\", \"35_35\"])]\n",
    "    sgd_bin_m1_df = sgd_bin_m1_all\n",
    "    baldassi_df = baldassi_all\n",
    "elif dataset == \"cifar10tl\":\n",
    "    our_df = our_all[our_all[\"layers\"].isin([\"525_525\", \"255_255\", \"135_135\", \"75_75\", \"35_35\"])]\n",
    "    sgd_bin_m1_df = sgd_bin_m1_all[sgd_bin_m1_all[\"layers\"].isin([\"70_70\", \"33_33\", \"18_18\", \"10_10\", \"5_5\"])]\n",
    "    sgd_small_df = sgd_small_all[sgd_small_all[\"layers\"].isin([\"70_70\", \"33_33\", \"18_18\", \"10_10\", \"5_5\"])]\n",
    "    baldassi_df = baldassi_all[baldassi_all[\"layers\"].isin([\"561_51\", \"264_24\", \"143_13\", \"77_7\", \"44_4\"])]\n",
    "elif dataset == \"cifar100tl\":\n",
    "    our_df = our_all[our_all[\"layers\"].isin([\"4095_4095\", \"2025_2025\", \"1035_1035\", \"525_525\", \"255_255\"])]\n",
    "    sgd_bin_m1_df = sgd_bin_m1_all[sgd_bin_m1_all[\"layers\"].isin([\"715_715\", \"312_312\", \"145_145\", \"70_70\", \"33_33\"])]\n",
    "    sgd_small_df = sgd_small_all[sgd_small_all[\"layers\"].isin([\"715_715\", \"312_312\", \"145_145\", \"70_70\", \"33_33\"])]\n",
    "    baldassi_df = baldassi_all[baldassi_all[\"layers\"].isin([\"5951_541\", \"2541_231\", \"1177_107\", \"561_51\", \"264_24\"])]\n",
    "elif dataset == \"fmnist\":\n",
    "    our_df = our_all[our_all[\"layers\"].isin([\"525_525\", \"255_255\", \"135_135\", \"75_75\", \"35_35\"])]\n",
    "    sgd_bin_m1_df = sgd_bin_m1_all[sgd_bin_m1_all[\"layers\"].isin([\"105_105\", \"44_44\", \"21_21\", \"11_11\", \"5_5\"])]\n",
    "    sgd_small_df = sgd_small_all[sgd_small_all[\"layers\"].isin([\"105_105\", \"44_44\", \"21_21\", \"11_11\", \"5_5\"])]\n",
    "    baldassi_df = baldassi_all[baldassi_all[\"layers\"].isin([\"880_80\", \"363_33\", \"165_15\", \"88_8\", \"44_4\"])]\n",
    " \n",
    "our_df = our_df.reset_index(drop=True)\n",
    "sgd_bin_m1_df = sgd_bin_m1_df.reset_index(drop=True)\n",
    "if dataset != \"prototypes\":\n",
    "    sgd_small_df = sgd_small_df.reset_index(drop=True)\n",
    "baldassi_df = baldassi_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the validation accuracy vs memory requirements\n",
    "fig = plt.figure()\n",
    "\n",
    "our_df = our_df.sort_values(by='memory')\n",
    "sgd_bin_m1_df = sgd_bin_m1_df.sort_values(by='memory')\n",
    "if dataset != \"prototypes\":\n",
    "    sgd_small_df = sgd_small_df.sort_values(by='memory')\n",
    "baldassi_df = baldassi_df.sort_values(by='memory')\n",
    "\n",
    "def plot(df, label, color, single_layer = False, sgd = False):\n",
    "    if sgd:\n",
    "        zorder = 1\n",
    "        linestyle = '-'\n",
    "        fmt = 'v'\n",
    "    else:\n",
    "        zorder = 2\n",
    "        linestyle = 'dashed' if single_layer else '-'\n",
    "        fmt = 'o'\n",
    "\n",
    "    plt.errorbar(df['memory']/8, df['mean_val_acc'], yerr=df['std_val_acc'], fmt=fmt, color=color, linestyle=linestyle, label=f\"{label}\", capsize=3, zorder=zorder)\n",
    "\n",
    "plot(our_df, 'Ours', \"black\")\n",
    "plot(baldassi_df, 'Baldassi et al. [10]', \"darkred\", single_layer=True)\n",
    "if dataset != \"prototypes\":\n",
    "    plot(sgd_small_df, 'FP input full-precision SGD', \"darkblue\", sgd=True)\n",
    "plot(sgd_bin_m1_df, 'Binary input full-precision SGD', \"darkgreen\", sgd=True)\n",
    " \n",
    "# Enhancing the plot\n",
    "if dataset == \"fmnist\":\n",
    "    plt.yticks(np.arange(39, 90, 5))\n",
    "    plt.ylim(38, 90)\n",
    "elif dataset == \"imagenettetl\":\n",
    "    # Print yticks with decimal values   \n",
    "    plt.yticks(np.arange(36, 93, 8))\n",
    "    plt.ylim(35, 93)\n",
    "elif dataset == \"prototypes\":\n",
    "    plt.yticks(np.arange(35, 99, 7))\n",
    "    plt.ylim(34, 99)\n",
    "elif dataset == \"cifar100tl\":\n",
    "    plt.yticks(np.arange(0, 60.5, 5))\n",
    "    plt.ylim(-1, 61)\n",
    "elif dataset == \"cifar10tl\":\n",
    "    plt.yticks(np.arange(32, 88, 5))\n",
    "    plt.ylim(31, 88)\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "\n",
    "plt.grid(True, which=\"both\")\n",
    "plt.xlabel('Memory requirements (bytes)')\n",
    "plt.ylabel('Test accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn = Path(f'fig/exp1a_{dataset}.pdf')\n",
    "# fig.savefig(fn, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD\n",
    "mul_cost = 10000\n",
    "add_cost = 10000\n",
    "\n",
    "if dataset != \"prototypes\":\n",
    "    sgd_small_df['operations'] = sgd_small_df['layers'].apply(lambda x: sum(a*b for a, b in zip(compute_operations(x), [mul_cost, add_cost])))\n",
    "sgd_bin_m1_df['operations'] = sgd_bin_m1_df['layers'].apply(lambda x: sum(a*b for a, b in zip(compute_operations(x), [mul_cost, add_cost])))\n",
    "\n",
    "# Localloss\n",
    "xnor_cost = 1\n",
    "popcount_cost = 10\n",
    "increment_cost = 10\n",
    "\n",
    "baldassi_df['operations'] = baldassi_df['layers'].apply(lambda x: sum(a*b for a, b in zip(compute_operations(x, binary=True, localloss=False), [xnor_cost, popcount_cost, increment_cost])))\n",
    "our_df['operations'] = our_df['layers'].apply(lambda x: sum(a*b for a, b in zip(compute_operations(x, binary=True, localloss=True), [xnor_cost, popcount_cost, increment_cost])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the validation accuracy vs memory requirements\n",
    "fig = plt.figure()\n",
    "\n",
    "our_df = our_df.sort_values(by='memory')\n",
    "sgd_bin_m1_df = sgd_bin_m1_df.sort_values(by='memory')\n",
    "if dataset != \"prototypes\":\n",
    "    sgd_small_df = sgd_small_df.sort_values(by='memory')\n",
    "baldassi_df = baldassi_df.sort_values(by='memory')\n",
    "\n",
    "def plot(df, label, color, single_layer = False, sgd = False):\n",
    "    if sgd:\n",
    "        zorder = 1\n",
    "        linestyle = '-'\n",
    "        fmt = 'v'\n",
    "    else:\n",
    "        zorder = 2\n",
    "        linestyle = 'dashed' if single_layer else '-'\n",
    "        fmt = 'o'\n",
    "\n",
    "    plt.errorbar(df['operations'], df['mean_val_acc'], yerr=df['std_val_acc'], fmt=fmt, color=color, linestyle=linestyle, label=f\"{label}\", capsize=3, zorder=zorder)\n",
    "\n",
    "plot(our_df, 'Ours', \"black\")\n",
    "plot(baldassi_df, 'Baldassi et al. [10]', \"darkred\", single_layer=True)\n",
    "if dataset != \"prototypes\":\n",
    "    plot(sgd_small_df, 'FP input full-precision SGD', \"darkblue\", sgd=True)\n",
    "plot(sgd_bin_m1_df, 'Binary input full-precision SGD', \"darkgreen\", sgd=True)\n",
    "\n",
    "# Enhancing the plot\n",
    "if dataset == \"fmnist\":\n",
    "    plt.yticks(np.arange(39, 90, 5))\n",
    "    plt.ylim(38, 90)\n",
    "    legend_loc = \"lower left\"\n",
    "elif dataset == \"imagenettetl\":\n",
    "    # Print yticks with decimal values   \n",
    "    plt.yticks(np.arange(36, 93, 8))\n",
    "    plt.ylim(35, 93)\n",
    "    legend_loc = \"lower left\"\n",
    "elif dataset == \"prototypes\":\n",
    "    plt.yticks(np.arange(35, 99, 7))\n",
    "    plt.ylim(34, 99)\n",
    "    legend_loc = \"lower right\"\n",
    "elif dataset == \"cifar100tl\":\n",
    "    plt.yticks(np.arange(0, 60.5, 5))\n",
    "    plt.ylim(-1, 61)\n",
    "    legend_loc = \"lower right\"\n",
    "elif dataset == \"cifar10tl\":\n",
    "    plt.yticks(np.arange(32, 88, 5))\n",
    "    plt.ylim(31, 88)\n",
    "    legend_loc = \"lower right\"\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.grid(True, which=\"both\")\n",
    "plt.xlabel('Number of Boolean gates')\n",
    "plt.ylabel('Test accuracy')\n",
    "plt.legend(loc=legend_loc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn = Path(f'fig/exp1b_{dataset}.pdf')\n",
    "# fig.savefig(fn, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_size_df = pd.read_csv(f'out/{dataset}/grouping_factor.csv')\n",
    "group_size_df['layers'] = group_size_df['layers'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare figure and axis again for the updated x-axis and lines between values\n",
    "fig = plt.figure()\n",
    "\n",
    "# Ensure sorted order by number of parameters for consistent plotting\n",
    "group_size_df = group_size_df.sort_values(by='grouping_factor')\n",
    "\n",
    "# Get layers 75, 525, 525, and 2025 and plot them with different colors\n",
    "for i, layer in enumerate([75, 135, 525, 2025]):\n",
    "    subset = group_size_df[group_size_df['layers'] == str(layer)]\n",
    "    if i == 0:\n",
    "        color = \"darkgreen\"\n",
    "    elif i == 1:\n",
    "        color = \"darkblue\"\n",
    "    elif i == 2:\n",
    "        color = \"grey\"\n",
    "    else:\n",
    "        color = \"darkred\"\n",
    "    \n",
    "    plt.errorbar(subset['grouping_factor'], subset['mean_val_acc'], yerr=subset['std_val_acc'], color=color, capsize=5, fmt=\"-o\", label=f\"Hidden layer size: {layer}\")\n",
    "\n",
    "# Enhancing the plot\n",
    "if dataset == \"fmnist\":\n",
    "    plt.yticks(np.arange(67, 89, 2))\n",
    "    plt.ylim(66, 88)\n",
    "elif dataset == \"imagenettetl\":\n",
    "    # Print yticks with decimal values   \n",
    "    plt.yticks(np.arange(83, 92, 1))\n",
    "    plt.ylim(82.5, 91.5)\n",
    "elif dataset == \"cifar10tl\":\n",
    "    plt.yticks(np.arange(55, 86, 2.5))\n",
    "    plt.ylim(54, 86)\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "\n",
    "plt.xlabel('Group size γ')\n",
    "plt.ylabel('Test accuracy')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn = Path(f'fig/exp2_{dataset}.pdf')\n",
    "# fig.savefig(fn, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"imagenettetl\":\n",
    "    our_df = our_all[(our_all[\"layers\"] == \"525_525\") | (our_all[\"layers\"] == \"255_255\") | (our_all[\"layers\"] == \"135_135\") | (our_all[\"layers\"] == \"75_75\") | (our_all[\"layers\"] == \"35_35\")]\n",
    "    baldassi_df_opt = baldassi_all[(baldassi_all[\"layers\"] == \"660_220\") | (baldassi_all[\"layers\"] == \"286_286\") | (baldassi_all[\"layers\"] == \"154_154\") | (baldassi_all[\"layers\"] == \"77_77\") | (baldassi_all[\"layers\"] == \"44_44\")]\n",
    "    baldassi_df_2l = baldassi_all[(baldassi_all[\"layers\"] == \"660_60_660_60\") | (baldassi_all[\"layers\"] == \"286_26_286_26\") | (baldassi_all[\"layers\"] == \"154_14_154_14\") | (baldassi_all[\"layers\"] == \"77_7_77_7\") | (baldassi_all[\"layers\"] == \"44_4_44_4\")]\n",
    "    baldassi_df_2l_opt = baldassi_all[(baldassi_all[\"layers\"] == \"660_220_660_220\") | (baldassi_all[\"layers\"] == \"286_286_286_286\") | (baldassi_all[\"layers\"] == \"154_154_154_154\") | (baldassi_all[\"layers\"] == \"77_77_77_77\") | (baldassi_all[\"layers\"] == \"44_44_44_44\")]\n",
    "elif dataset == \"cifar10tl\":\n",
    "    our_df = our_all[(our_all[\"layers\"] == \"525_525\") | (our_all[\"layers\"] == \"255_255\") | (our_all[\"layers\"] == \"135_135\") | (our_all[\"layers\"] == \"75_75\") | (our_all['layers'] == '35_35')]\n",
    "    baldassi_df_opt = baldassi_all[(baldassi_all[\"layers\"] == \"561_51\") | (baldassi_all[\"layers\"] == \"264_88\") | (baldassi_all[\"layers\"] == \"143_143\") | (baldassi_all[\"layers\"] == \"77_77\") | (baldassi_all[\"layers\"] == \"44_44\")]\n",
    "    baldassi_df_2l = baldassi_all[(baldassi_all[\"layers\"] == \"561_51_561_51\") | (baldassi_all[\"layers\"] == \"264_24_264_24\") | (baldassi_all[\"layers\"] == \"143_13_143_13\") | (baldassi_all[\"layers\"] == \"77_7_77_7\") | (baldassi_all[\"layers\"] == \"44_4_44_4\")]\n",
    "    baldassi_df_2l_opt = baldassi_all[(baldassi_all[\"layers\"] == \"561_51_561_51\") | (baldassi_all[\"layers\"] == \"264_88_264_88\") | (baldassi_all[\"layers\"] == \"143_143_143_143\") | (baldassi_all[\"layers\"] == \"77_77_77_77\") | (baldassi_all[\"layers\"] == \"44_44_44_44\")]\n",
    "elif dataset == \"fmnist\":\n",
    "    our_df = our_all[(our_all[\"layers\"] == \"525_525\") | (our_all[\"layers\"] == \"255_255\") | (our_all[\"layers\"] == \"135_135\") | (our_all[\"layers\"] == \"75_75\") | (our_all[\"layers\"] == \"35_35\")]\n",
    "    baldassi_df_opt = baldassi_all[(baldassi_all[\"layers\"] == \"880_80\") | (baldassi_all[\"layers\"] == \"363_33\") | (baldassi_all[\"layers\"] == \"165_33\") | (baldassi_all[\"layers\"] == \"88_8\") | (baldassi_all[\"layers\"] == \"44_44\")]\n",
    "    baldassi_df_2l = baldassi_all[(baldassi_all[\"layers\"] == \"880_80_880_80\") | (baldassi_all[\"layers\"] == \"363_33_363_33\") | (baldassi_all[\"layers\"] == \"165_15_165_15\") | (baldassi_all[\"layers\"] == \"88_8_88_8\") | (baldassi_all[\"layers\"] == \"44_4_44_4\")]\n",
    "    baldassi_df_2l_opt = baldassi_all[(baldassi_all[\"layers\"] == \"880_80_880_80\") | (baldassi_all[\"layers\"] == \"363_33_363_33\") | (baldassi_all[\"layers\"] == \"165_33_165_33\") | (baldassi_all[\"layers\"] == \"88_8_88_8\") | (baldassi_all[\"layers\"] == \"44_44_44_44\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the validation accuracy vs memory requirements\n",
    "fig = plt.figure()\n",
    "\n",
    "def plot(df, label, color, single_layer = False, sgd = False):\n",
    "    df.sort_values(by='memory', inplace=True)\n",
    "    if sgd:\n",
    "        zorder = 1\n",
    "        linestyle = '-'\n",
    "        fmt = 'v'\n",
    "    else:\n",
    "        zorder = 2\n",
    "        linestyle = 'dashed' if single_layer else '-'\n",
    "        fmt = 'o'\n",
    "\n",
    "    plt.errorbar(df['memory']/8, df['mean_val_acc'], yerr=df['std_val_acc'], fmt=fmt, color=color, linestyle=linestyle, label=f\"{label}\", capsize=3, zorder=zorder)\n",
    "\n",
    "plot(our_df, 'Ours - 2 hidden layers', \"black\")\n",
    "plot(baldassi_df_2l, 'Baldassi et al. [10] - 2 hidden layers', \"darkgreen\", sgd=True)\n",
    "plot(baldassi_df_opt, 'Baldassi et al. [10] enhanced - 1 hidden layer', \"darkred\", single_layer=True)\n",
    "plot(baldassi_df_2l_opt, 'Baldassi et al. [10] enhanced - 2 hidden layers', \"darkblue\", sgd=True)\n",
    "\n",
    "# Enhancing the plot\n",
    "if dataset == \"fmnist\":\n",
    "    plt.yticks(np.arange(39, 89, 3.5))\n",
    "    plt.ylim(38, 89)\n",
    "elif dataset == \"imagenettetl\":\n",
    "    # Print yticks with decimal values   \n",
    "    plt.yticks(np.arange(27, 93, 8))\n",
    "    plt.ylim(25, 93)\n",
    "elif dataset == \"prototypes\":\n",
    "    plt.yticks(np.arange(35, 99, 7))\n",
    "    plt.ylim(34, 99)\n",
    "elif dataset == \"cifar10tl\":\n",
    "    plt.yticks(np.arange(16.5, 87.5, 5))\n",
    "    plt.ylim(15.5, 87.5)\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "\n",
    "plt.grid(True, which=\"both\")\n",
    "plt.xlabel('Memory requirements (bytes)')\n",
    "plt.ylabel('Test accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn = Path(f'fig/exp3_{dataset}.pdf')\n",
    "# fig.savefig(fn, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_small_all = pd.read_csv(f'out/{dataset}/adam.csv')\n",
    "adam_small_all['mean_val_acc'] = adam_small_all['mean_val_acc']*100\n",
    "adam_small_all['std_val_acc'] = adam_small_all['std_val_acc']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_df = our_all[our_all['layers'].apply(lambda x: '1035' in x)].copy()\n",
    "sgd_df = sgd_small_all[sgd_small_all['layers'].apply(lambda x: '1035' in x)].copy()\n",
    "adam_df = adam_small_all[adam_small_all['layers'].apply(lambda x: '1035' in x)].copy()\n",
    "\n",
    "# Compute the number of layers for each architecture\n",
    "our_df.loc[:, '#layers'] = our_df['layers'].apply(lambda x: len(x.split('_')))\n",
    "sgd_df.loc[:, '#layers'] = sgd_df['layers'].apply(lambda x: len(x.split('_')))\n",
    "adam_df.loc[:, '#layers'] = adam_df['layers'].apply(lambda x: len(x.split('_')))\n",
    "\n",
    "# Prepare figure and axis again for the updated x-axis and lines between values\n",
    "fig = plt.figure()\n",
    "\n",
    "sgd_color = \"darkgreen\"\n",
    "adam_color = \"darkblue\"\n",
    "sgd_alpha = 0.4\n",
    "adam_alpha = 0.4\n",
    "\n",
    "def plot(df, label, color, optimizer=None, alpha=1.0):\n",
    "    df.sort_values(by='#layers', inplace=True)\n",
    "    if optimizer == 'sgd':\n",
    "        zorder = 1\n",
    "        linestyle = 'dashed'\n",
    "        fmt = 'v'\n",
    "    elif optimizer == 'adam':\n",
    "        zorder = 2\n",
    "        linestyle = 'dotted'\n",
    "        fmt = 's'\n",
    "    else:\n",
    "        zorder = 3\n",
    "        linestyle = '-'\n",
    "        fmt = 'o'\n",
    "\n",
    "    plt.errorbar(df['#layers'], df['mean_val_acc'], yerr=df['std_val_acc'],\n",
    "                 fmt=fmt, color=color, linestyle=linestyle, label=f\"{label}\",\n",
    "                 capsize=3, zorder=zorder, alpha=alpha)\n",
    "\n",
    "plot(our_df, 'Ours', color=\"black\")\n",
    "plot(sgd_df, 'Full-precision SGD', color=sgd_color, optimizer='sgd', alpha=sgd_alpha)\n",
    "plot(adam_df, 'Full-precision Adam', color=adam_color, optimizer='adam', alpha=adam_alpha)\n",
    "# # Adjusted function to apply shades based on the first layer within each learning algorithm\n",
    "# def plot(df, label, color, optimizer=None):\n",
    "#     df.sort_values(by='#layers', inplace=True)\n",
    "#     if optimizer == 'sgd':\n",
    "#         zorder = 1\n",
    "#         linestyle = 'dashed'\n",
    "#         fmt = 'v'\n",
    "#     elif optimizer == 'adam':\n",
    "#         zorder = 2\n",
    "#         linestyle = 'dotted'\n",
    "#         fmt = 's'\n",
    "#     else:\n",
    "#         zorder = 3\n",
    "#         linestyle = '-'\n",
    "#         fmt = 'o'\n",
    "\n",
    "#     plt.errorbar(df['#layers'], df['mean_val_acc'], yerr=df['std_val_acc'], fmt=fmt, color=color, linestyle=linestyle, label=f\"{label}\", capsize=3, zorder=zorder)    \n",
    "    \n",
    "# plot(our_df, 'Ours', color=\"black\")\n",
    "# plot(sgd_df, 'Full-precision SGD', color=\"silver\", optimizer='sgd')\n",
    "# plot(adam_df, 'Full-precision Adam', color=\"dimgray\", optimizer='adam')\n",
    "\n",
    "# Enhancing the plot\n",
    "if dataset == \"fmnist\":\n",
    "    plt.yticks(np.arange(81, 91, 1.5))\n",
    "    plt.ylim(80, 91)\n",
    "elif dataset == \"imagenettetl\":\n",
    "    plt.yticks(np.arange(0, 101, 10))\n",
    "    plt.ylim(-1, 101)\n",
    "elif dataset == \"cifar10tl\":\n",
    "    plt.yticks(np.arange(5, 96, 10))\n",
    "    plt.ylim(4, 96)\n",
    "    \n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "\n",
    "plt.xticks(np.arange(1, 11, 1))\n",
    "plt.xlabel('Number of layers')\n",
    "plt.ylabel('Test accuracy')\n",
    "plt.legend(loc='lower left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn = Path(f'fig/exp4_{dataset}.pdf')\n",
    "# fig.savefig(fn, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPENDIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_bin_all = pd.read_csv(f'out/{dataset}/adam_bin.csv')\n",
    "if dataset != \"prototypes\":\n",
    "    adam_small_all = pd.read_csv(f'out/{dataset}/adam.csv')\n",
    "\n",
    "adam_bin_all['mean_val_acc'] = adam_bin_all['mean_val_acc']*100\n",
    "adam_bin_all['std_val_acc'] = adam_bin_all['std_val_acc']*100\n",
    "if dataset != \"prototypes\":\n",
    "    adam_small_all['mean_val_acc'] = adam_small_all['mean_val_acc']*100\n",
    "    adam_small_all['std_val_acc'] = adam_small_all['std_val_acc']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam memory\n",
    "for i, row in adam_bin_all.iterrows():\n",
    "    mem_w, mem_w_ll, mem_w_gl, mem_h, mem_d = compute_memory(row['layers'], adam=True)\n",
    "    mem_bin_adam[row[\"layers\"]] = input_dim*dataset_size*1 + mem_w[row[\"layers\"]]*32 + mem_h[row[\"layers\"]]*32 + mem_d[row[\"layers\"]]*32\n",
    "if dataset != \"prototypes\":\n",
    "    for i, row in adam_small_all.iterrows():\n",
    "        mem_w, mem_w_ll, mem_w_gl, mem_h, mem_d = compute_memory(row['layers'], adam=True)\n",
    "        mem_small_adam[row[\"layers\"]] = input_dim*dataset_size//32*32 + mem_w[row[\"layers\"]]*32 + mem_h[row[\"layers\"]]*32 + mem_d[row[\"layers\"]]*32\n",
    "\n",
    "adam_bin_all['memory'] = adam_bin_all['layers'].apply(lambda x: mem_bin_adam[x])\n",
    "if dataset != \"prototypes\":\n",
    "    adam_small_all['memory'] = adam_small_all['layers'].apply(lambda x: mem_small_adam[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_bin_df = adam_bin_all\n",
    "adam_bin_df = adam_bin_df.reset_index(drop=True)\n",
    "\n",
    "if dataset != \"prototypes\":\n",
    "    adam_small_df = adam_small_all[~adam_small_all['layers'].str.contains('1035')]\n",
    "    adam_small_df = adam_small_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the validation accuracy vs memory requirements\n",
    "fig = plt.figure()\n",
    "\n",
    "our_df = our_df.sort_values(by='memory')\n",
    "adam_bin_df = adam_bin_df.sort_values(by='memory')\n",
    "if dataset != \"prototypes\":\n",
    "    adam_small_df = adam_small_df.sort_values(by='memory')\n",
    "\n",
    "def plot(df, label, color, single_layer = False, sgd = False):\n",
    "    if sgd:\n",
    "        zorder = 1\n",
    "        linestyle = '-'\n",
    "        fmt = 'v'\n",
    "    else:\n",
    "        zorder = 2\n",
    "        linestyle = 'dashed' if single_layer else '-'\n",
    "        fmt = 'o'\n",
    "\n",
    "    plt.errorbar(df['memory']/8, df['mean_val_acc'], yerr=df['std_val_acc'], fmt=fmt, color=color, linestyle=linestyle, label=f\"{label}\", capsize=3, zorder=zorder)\n",
    "\n",
    "plot(our_df, 'Ours', \"black\")\n",
    "if dataset != \"prototypes\":\n",
    "    plot(adam_small_df, 'FP input full-precision Adam', \"darkblue\", sgd=True)\n",
    "plot(adam_bin_df, 'Binary input full-precision Adam', \"darkgreen\", sgd=True)\n",
    "\n",
    "# Enhancing the plot\n",
    "if dataset == \"fmnist\":\n",
    "    plt.yticks(np.arange(30, 91, 6))\n",
    "    plt.ylim(29, 91)\n",
    "elif dataset == \"imagenettetl\":\n",
    "    # Print yticks with decimal values   \n",
    "    plt.yticks(np.arange(5, 94, 8))\n",
    "    plt.ylim(4, 94)\n",
    "elif dataset == \"prototypes\":\n",
    "    plt.yticks(np.arange(28, 99, 7))\n",
    "    plt.ylim(27, 99)\n",
    "elif dataset == \"cifar100tl\":\n",
    "    plt.yticks(np.arange(0, 60.5, 5))\n",
    "    plt.ylim(-1, 61)\n",
    "elif dataset == \"cifar10tl\":\n",
    "    plt.yticks(np.arange(5, 86, 8))\n",
    "    plt.ylim(4, 86)\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "\n",
    "plt.grid(True, which=\"both\")\n",
    "plt.xlabel('Memory requirements (bytes)')\n",
    "plt.ylabel('Test accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn = Path(f'fig/exp_appendix3a_{dataset}.pdf')\n",
    "# fig.savefig(fn, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam\n",
    "mul_cost = 10000\n",
    "add_cost = 10000\n",
    "\n",
    "if dataset != \"prototypes\":\n",
    "    adam_small_df['operations'] = adam_small_df['layers'].apply(lambda x: sum(a*b for a, b in zip(compute_operations(x, optimizer=\"adam\"), [mul_cost, add_cost])))\n",
    "adam_bin_df['operations'] = adam_bin_df['layers'].apply(lambda x: sum(a*b for a, b in zip(compute_operations(x, optimizer=\"adam\"), [mul_cost, add_cost])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the validation accuracy vs memory requirements\n",
    "fig = plt.figure()\n",
    "\n",
    "adam_bin_df = adam_bin_df.sort_values(by='memory')\n",
    "if dataset != \"prototypes\":\n",
    "    adam_small_df = adam_small_df.sort_values(by='memory')\n",
    "\n",
    "def plot(df, label, color, single_layer = False, sgd = False):\n",
    "    if sgd:\n",
    "        zorder = 1\n",
    "        linestyle = '-'\n",
    "        fmt = 'v'\n",
    "    else:\n",
    "        zorder = 2\n",
    "        linestyle = 'dashed' if single_layer else '-'\n",
    "        fmt = 'o'\n",
    "\n",
    "    plt.errorbar(df['operations'], df['mean_val_acc'], yerr=df['std_val_acc'], fmt=fmt, color=color, linestyle=linestyle, label=f\"{label}\", capsize=3, zorder=zorder)\n",
    "\n",
    "plot(our_df, 'Ours', \"black\")\n",
    "if dataset != \"prototypes\":\n",
    "    plot(adam_small_df, 'FP input full-precision Adam', \"darkblue\", sgd=True)\n",
    "plot(adam_bin_df, 'Binary input full-precision Adam', \"darkgreen\", sgd=True)\n",
    "\n",
    "# Enhancing the plot\n",
    "if dataset == \"fmnist\":\n",
    "    plt.yticks(np.arange(30, 91, 6))\n",
    "    plt.ylim(29, 91)\n",
    "    legend_loc = \"lower left\"\n",
    "elif dataset == \"imagenettetl\":\n",
    "    # Print yticks with decimal values   \n",
    "    plt.yticks(np.arange(5, 94, 8))\n",
    "    plt.ylim(4, 94)\n",
    "    legend_loc = \"lower left\"\n",
    "elif dataset == \"prototypes\":\n",
    "    plt.yticks(np.arange(28, 99, 7))\n",
    "    plt.ylim(27, 99)\n",
    "elif dataset == \"cifar100tl\":\n",
    "    plt.yticks(np.arange(0, 60.5, 5))\n",
    "    plt.ylim(-1, 61)\n",
    "elif dataset == \"cifar10tl\":\n",
    "    plt.yticks(np.arange(5, 86, 8))\n",
    "    plt.ylim(4, 86)\n",
    "    legend_loc = \"lower left\"\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.grid(True, which=\"both\")\n",
    "plt.xlabel('Number of Boolean gates')\n",
    "plt.ylabel('Test accuracy')\n",
    "plt.legend(loc=legend_loc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn = Path(f'fig/exp_appendix3b_{dataset}.pdf')\n",
    "# fig.savefig(fn, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rob_df = pd.read_csv(f'out/{dataset}/rob.csv')\n",
    "rob_df['layers'] = rob_df['layers'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare figure and axis again for the updated x-axis and lines between values\n",
    "fig = plt.figure()\n",
    "\n",
    "# Ensure sorted order by number of parameters for consistent plotting\n",
    "rob_df = rob_df.sort_values(by='rob')\n",
    "\n",
    "# Get layers 75, 525, 525, and 2025 and plot them with different colors\n",
    "for i, layer in enumerate([75, 135, 525, 2025]):\n",
    "    subset = rob_df[rob_df['layers'] == str(layer)]\n",
    "    if i == 0:\n",
    "        color = \"darkgreen\"\n",
    "    elif i == 1:\n",
    "        color = \"darkblue\"\n",
    "    elif i == 2:\n",
    "        color = \"grey\"\n",
    "    else:\n",
    "        color = \"darkred\"\n",
    "    \n",
    "    plt.errorbar(subset['rob'], subset['mean_val_acc'], yerr=subset['std_val_acc'], color=color, capsize=5, fmt=\"-o\", label=f\"Hidden layer size: {layer}\")\n",
    "\n",
    "# Enhancing the plot\n",
    "if dataset == \"fmnist\":\n",
    "    plt.yticks(np.arange(77, 88, 1))\n",
    "    plt.ylim(76, 88)\n",
    "elif dataset == \"imagenettetl\":\n",
    "    # Print yticks with decimal values   \n",
    "    plt.yticks(np.arange(83.5, 92, 1))\n",
    "    plt.ylim(82.5, 92.5)\n",
    "elif dataset == \"cifar10tl\":\n",
    "    plt.yticks(np.arange(75, 85, 1))\n",
    "    plt.ylim(74, 85)\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "\n",
    "plt.xticks([0.0, 0.25, 0.5, 0.75, 1.0])\n",
    "plt.xlabel(r\"Robustness $r$\")\n",
    "plt.ylabel('Test accuracy')\n",
    "# plt.xscale('log')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn = Path(f'fig/exp_appendix1_{dataset}.pdf')\n",
    "# fig.savefig(fn, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping layer size optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_size_df = pd.read_csv(f'out/{dataset}/baldassi.csv')\n",
    "# Filter rows that have max 2 layers\n",
    "group_size_df = group_size_df[group_size_df['layers'].apply(lambda x: len(x.split('_')) == 2)]\n",
    "group_size_df['grouping_factor'] = group_size_df['layers'].apply(lambda x: int(x.split('_')[1]))\n",
    "group_size_df['layers'] = group_size_df['layers'].apply(lambda x: str(x.split('_')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare figure and axis again for the updated x-axis and lines between values\n",
    "fig = plt.figure()\n",
    "\n",
    "# Ensure sorted order by number of parameters for consistent plotting\n",
    "group_size_df = group_size_df.sort_values(by='grouping_factor')\n",
    "\n",
    "# Plot each layer with different colors\n",
    "for i, layer in enumerate(group_size_df['layers'].unique()):\n",
    "    subset = group_size_df[group_size_df['layers'] == layer]\n",
    "    \n",
    "    if i == 0:\n",
    "        color = \"darkgreen\"\n",
    "    elif i == 1:\n",
    "        color = \"darkblue\"\n",
    "    elif i == 2:\n",
    "        color = \"grey\"\n",
    "    elif i == 3:\n",
    "        color = \"darkred\"\n",
    "    else:\n",
    "        color = \"black\"\n",
    "        \n",
    "    # print(layer, subset.loc[subset['mean_val_acc'].idxmax()]['grouping_factor'])\n",
    "    plt.errorbar(subset['grouping_factor'], subset['mean_val_acc'], yerr=subset['std_val_acc'], color=color, capsize=5, fmt=\"-o\", label=f\"Hidden layer size: {layer}\")\n",
    "\n",
    "# Enhancing the plot\n",
    "if dataset == \"fmnist\":\n",
    "    plt.yticks(np.arange(10, 91, 10))\n",
    "    plt.ylim(8, 92)\n",
    "elif dataset == \"imagenettetl\":\n",
    "    plt.yticks(np.arange(45, 96, 5))\n",
    "    plt.ylim(44, 96)\n",
    "elif dataset == \"cifar10tl\":\n",
    "    plt.yticks(np.arange(5, 86, 10))\n",
    "    plt.ylim(3, 87)\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    \n",
    "plt.xscale('log')\n",
    "plt.xlabel('Baldassi et al. [10] classification layer size ')\n",
    "plt.ylabel('Test accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn = Path(f'fig/exp_appendix2_{dataset}.pdf')\n",
    "# fig.savefig(fn, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localloss_all = pd.read_csv(f'out/uci/our.csv')\n",
    "baldassi_all = pd.read_csv(f'out/uci/baldassi.csv')\n",
    "\n",
    "localloss_all['layers'] = localloss_all['layers'].astype(str)\n",
    "baldassi_all['layers'] = baldassi_all['layers'].astype(str)\n",
    "# sgd_all['mean_val_acc'] = sgd_all['mean_val_acc']*100\n",
    "# sgd_all['std_val_acc'] = sgd_all['std_val_acc']*100\n",
    "\n",
    "# Take only rows with layers = 135_135\n",
    "# localloss_all = localloss_all[(localloss_all['layers'] == \"135_135\") | (localloss_all['layers'] == \"55_55\")]\n",
    "\n",
    "# Extracting relevant columns based on actual names\n",
    "df_table_ll = localloss_all[[\n",
    "    \"dataset\", \"layers\", \"mean_val_acc\", \"std_val_acc\"\n",
    "]].copy()\n",
    "\n",
    "df_table_baldassi = baldassi_all[[\n",
    "    \"dataset\", \"layers\", \"mean_val_acc\", \"std_val_acc\"\n",
    "]].copy()\n",
    "\n",
    "# Formatting the accuracy values as \"acc ± std\" with 2 decimal places\n",
    "df_table_ll[\"mean_val_acc\"] = df_table_ll.apply(\n",
    "    lambda row: f\"{row['mean_val_acc']:.2f} ± {row['std_val_acc']:.2f}\", axis=1\n",
    ")\n",
    "df_table_baldassi[\"mean_val_acc\"] = df_table_baldassi.apply(\n",
    "    lambda row: f\"{row['mean_val_acc']:.2f} ± {row['std_val_acc']:.2f}\", axis=1\n",
    ")\n",
    "\n",
    "# Dropping the standard deviation column as it's now merged with accuracy\n",
    "df_table_ll = df_table_ll.drop(columns=[\"std_val_acc\"]).sort_values([\"dataset\",\"layers\"])\n",
    "df_table_baldassi = df_table_baldassi.drop(columns=[\"std_val_acc\"]).sort_values([\"dataset\",\"layers\"])\n",
    "\n",
    "# Renaming columns for better visualization\n",
    "df_table_ll.columns = [\"Dataset\", \"Layers\", \"OUR Validation Accuracy\"]\n",
    "df_table_baldassi.columns = [\"Dataset\", \"Layers\", \"baldassi Validation Accuracy\"]\n",
    "\n",
    "# Split the layers column into two integers and multiply them to get the dimension\n",
    "df_table_ll['Layer_Dim'] = df_table_ll['Layers'].apply(lambda x: np.prod([int(i) for i in x.split('_')]))\n",
    "df_table_baldassi['Layer_Dim'] = df_table_baldassi['Layers'].apply(lambda x: np.prod([int(i) for i in x.split('_')]))\n",
    "\n",
    "# Sort by Dataset and Layer_Dim\n",
    "df_table_ll = df_table_ll.sort_values(by=['Dataset', 'Layer_Dim'], ascending=[True, False])\n",
    "df_table_baldassi = df_table_baldassi.sort_values(by=['Dataset', 'Layer_Dim'], ascending=[True, False])\n",
    "\n",
    "# Create a rank per dataset based on the Layer_Dim for OUR and baldassi tables\n",
    "df_table_ll['Rank'] = df_table_ll.groupby('Dataset')['Layer_Dim'].rank(ascending=False, method='first').astype(int)\n",
    "df_table_baldassi['Rank'] = df_table_baldassi.groupby('Dataset')['Layer_Dim'].rank(ascending=False, method='first').astype(int)\n",
    "\n",
    "# Drop Layer_Dim column\n",
    "df_table_ll = df_table_ll.drop(columns=['Layer_Dim'])\n",
    "df_table_baldassi = df_table_baldassi.drop(columns=['Layer_Dim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Create a scatter plot to compare localloss vs sgd accuracies\n",
    "fig = plt.figure()\n",
    "\n",
    "# Extract accuracies from the table\n",
    "localloss_acc = df_table_ll['OUR Validation Accuracy'].str.split(' ± ').str[0].astype(float)\n",
    "baldassi_acc = df_table_baldassi['baldassi Validation Accuracy'].str.split(' ± ').str[0].astype(float)\n",
    "\n",
    "localloss_acc.reset_index(drop=True, inplace=True)\n",
    "baldassi_acc.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Plot the reference line x=y\n",
    "plt.plot([0, 100], [0, 100], color='black', linestyle='dashed')\n",
    "\n",
    "colors = ['blue', 'green', 'red']\n",
    "labels = ['Large architectures', \"Medium architectures\", \"Small architectures\"]\n",
    "\n",
    "# Plot the scatter plot\n",
    "for i in range(len(localloss_acc)):\n",
    "    plt.scatter(localloss_acc[i], baldassi_acc[i], color=colors[i%3])\n",
    "\n",
    "# Create a legend\n",
    "for i in range(len(labels)):\n",
    "    plt.scatter([], [], color=colors[i], label=labels[i])\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlim(48, 102)\n",
    "plt.ylim(48, 102)\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "plt.gca().xaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "\n",
    "plt.xlabel('Our proposed solution test accuracy')\n",
    "plt.ylabel('Baldassi et al. [10] test accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# fn = Path(f'fig/exp_appendix3_uci.pdf')\n",
    "# fig.savefig(fn, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_all_learning = pd.read_csv(f'out/{dataset}/our_per_step.csv')\n",
    "sgd_bin_all_learning = pd.read_csv(f'out/{dataset}/sgd_bin_per_step.csv')\n",
    "if dataset != \"prototypes\":\n",
    "    sgd_small_all_learning = pd.read_csv(f'out/{dataset}/sgd_per_step.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "our_df = our_all_learning[(our_all_learning[\"layers\"] == \"525_525\")]\n",
    "\n",
    "if dataset == \"imagenettetl\":\n",
    "    sgd_bin_m1_df = sgd_bin_all_learning[(sgd_bin_all_learning[\"layers\"] == \"81_81\")]\n",
    "    sgd_small_df = sgd_small_all_learning[(sgd_small_all_learning[\"layers\"] == \"81_81\")]\n",
    "elif dataset == \"cifar10tl\":\n",
    "    sgd_bin_m1_df = sgd_bin_all_learning[ (sgd_bin_all_learning[\"layers\"] == \"70_70\")]\n",
    "    sgd_small_df = sgd_small_all_learning[(sgd_small_all_learning[\"layers\"] == \"70_70\")]\n",
    "elif dataset == \"fmnist\":\n",
    "    sgd_bin_m1_df = sgd_bin_all_learning[(sgd_bin_all_learning[\"layers\"] == \"105_105\")]\n",
    "    sgd_small_df = sgd_small_all_learning[(sgd_small_all_learning[\"layers\"] == \"105_105\")]\n",
    "\n",
    "our_df = our_df.reset_index(drop=True)\n",
    "sgd_bin_m1_df = sgd_bin_m1_df.reset_index(drop=True)\n",
    "if dataset != \"prototypes\":\n",
    "    sgd_small_df = sgd_small_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_sgd_small, mem_sgd_bin_m1, mem_ll, mem_baldassi = {}, {}, {}, {}\n",
    "for i, row in our_df.iterrows():\n",
    "    mem_w, mem_w_ll, mem_w_gl, mem_h, mem_d = compute_memory(row['layers'])\n",
    "    mem_ll[row[\"layers\"]] = input_dim*dataset_size*1 + mem_w[row[\"layers\"]]*8 + mem_w_ll[row[\"layers\"]]*1 + mem_h[row[\"layers\"]]*8\n",
    "if dataset != \"prototypes\":\n",
    "    for i, row in sgd_small_df.iterrows():\n",
    "        mem_w, mem_w_ll, mem_w_gl, mem_h, mem_d = compute_memory(row['layers'])\n",
    "        mem_sgd_small[row[\"layers\"]] = input_dim*dataset_size//32*32 + mem_w[row[\"layers\"]]*32 + mem_h[row[\"layers\"]]*32 + mem_d[row[\"layers\"]]*32\n",
    "for i, row in sgd_bin_m1_df.iterrows():\n",
    "    mem_w, mem_w_ll, mem_w_gl, mem_h, mem_d = compute_memory(row['layers'])\n",
    "    mem_sgd_bin_m1[row[\"layers\"]] = input_dim*dataset_size*1 + mem_w[row[\"layers\"]]*32 + mem_h[row[\"layers\"]]*32 + mem_d[row[\"layers\"]]*32\n",
    "    \n",
    "our_df['memory'] = our_df['layers'].apply(lambda x: mem_ll[x])\n",
    "sgd_bin_m1_df['memory'] = sgd_bin_m1_df['layers'].apply(lambda x: mem_sgd_bin_m1[x])\n",
    "if dataset != \"prototypes\":\n",
    "    sgd_small_df['memory'] = sgd_small_df['layers'].apply(lambda x: mem_sgd_small[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_bin_m1_df['mean_val_acc'] = sgd_bin_m1_df['mean_val_acc']*100\n",
    "sgd_bin_m1_df['std_val_acc'] = sgd_bin_m1_df['std_val_acc']*100\n",
    "sgd_bin_m1_df['mean_train_acc'] = sgd_bin_m1_df['mean_train_acc']*100\n",
    "sgd_bin_m1_df['std_train_acc'] = sgd_bin_m1_df['std_train_acc']*100\n",
    "if dataset != \"prototypes\":\n",
    "    sgd_small_df['mean_val_acc'] = sgd_small_df['mean_val_acc']*100\n",
    "    sgd_small_df['std_val_acc'] = sgd_small_df['std_val_acc']*100\n",
    "    sgd_small_df['mean_train_acc'] = sgd_small_df['mean_train_acc']*100\n",
    "    sgd_small_df['std_train_acc'] = sgd_small_df['std_train_acc']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to get unique layers sorted by memory\n",
    "def get_sorted_layers(df):\n",
    "    layers_mem = df.groupby('layers').first().reset_index()[['layers', 'memory']]\n",
    "    return layers_mem.sort_values('memory')['layers'].tolist()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# Plot with std shadow for Ours (skip step 0)\n",
    "layers_ours = get_sorted_layers(our_df)\n",
    "for idx, layer in enumerate(layers_ours):\n",
    "    subset = our_df[(our_df['layers'] == layer) & (our_df['step'] != 0)]\n",
    "    ax.plot(subset['step'], subset['mean_val_acc'], label=f'Ours', color=\"black\")\n",
    "    ax.fill_between(\n",
    "        subset['step'],\n",
    "        subset['mean_val_acc'] - subset['std_val_acc'],\n",
    "        subset['mean_val_acc'] + subset['std_val_acc'],\n",
    "        color=\"black\", alpha=0.15\n",
    "    )\n",
    "\n",
    "# Plot with std shadow for SGD Binary\n",
    "layers_sgd_bin = get_sorted_layers(sgd_bin_m1_df)\n",
    "for idx, layer in enumerate(layers_sgd_bin):\n",
    "    subset = sgd_bin_m1_df[sgd_bin_m1_df['layers'] == layer].copy()\n",
    "    subset['step'] = subset['step'] + 1\n",
    "    ax.plot(subset['step'], subset['mean_val_acc'], label=f\"Binary input full-precision SGD\", color=\"darkgreen\")\n",
    "    ax.fill_between(\n",
    "        subset['step'],\n",
    "        subset['mean_val_acc'] - subset['std_val_acc'],\n",
    "        subset['mean_val_acc'] + subset['std_val_acc'],\n",
    "        color=\"darkgreen\", alpha=0.15\n",
    "    )\n",
    "\n",
    "# Plot with std shadow for SGD Small\n",
    "if dataset != \"prototypes\":\n",
    "    layers_sgd_small = get_sorted_layers(sgd_small_df)\n",
    "    for idx, layer in enumerate(layers_sgd_small):\n",
    "        subset = sgd_small_df[sgd_small_df['layers'] == layer].copy()\n",
    "        subset['step'] = subset['step'] + 1\n",
    "        ax.plot(subset['step'], subset['mean_val_acc'], label=f'FP input full-precision SGD', color=\"darkblue\")\n",
    "        ax.fill_between(\n",
    "            subset['step'],\n",
    "            subset['mean_val_acc'] - subset['std_val_acc'],\n",
    "            subset['mean_val_acc'] + subset['std_val_acc'],\n",
    "            color=\"darkblue\", alpha=0.15\n",
    "        )\n",
    "\n",
    "# Enhancing the plot\n",
    "if dataset == \"fmnist\":\n",
    "    plt.yticks(np.arange(26, 90, 7))\n",
    "    plt.ylim(25, 91)\n",
    "elif dataset == \"imagenettetl\":\n",
    "    # Print yticks with decimal values   \n",
    "    plt.yticks(np.arange(17, 96, 7))\n",
    "    plt.ylim(16, 95)\n",
    "elif dataset == \"prototypes\":\n",
    "    plt.yticks(np.arange(32, 99, 8))\n",
    "    plt.ylim(30, 98)\n",
    "elif dataset == \"cifar10tl\":\n",
    "    plt.yticks(np.arange(19, 86, 6))\n",
    "    plt.ylim(18, 86)\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "\n",
    "plt.grid(True, which=\"both\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Test accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn = Path(f'fig/exp_add1_{dataset}.pdf')\n",
    "# fig.savefig(fn, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catastrophic Forgetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_all_forget = pd.read_csv(f'out/{dataset}/our_forget.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot test accuracy vs weight_clip for our_all_forget\n",
    "\n",
    "# Compute log2(weight_clip) + 1 for x-axis\n",
    "df = our_all_forget.sort_values('weight_clip').copy()\n",
    "df['log2_weight_clip_plus1'] = np.log2(df['weight_clip']) + 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "\n",
    "ax.errorbar(\n",
    "    df['log2_weight_clip_plus1'],\n",
    "    df['mean_val_acc'],\n",
    "    yerr=df['std_val_acc'],\n",
    "    fmt='-o',\n",
    "    color='black',\n",
    "    capsize=4,\n",
    "    label='Test accuracy'\n",
    ")\n",
    "\n",
    "# Enhancing the plot\n",
    "plt.yticks(np.arange(10, 91, 10))\n",
    "plt.ylim(5, 95)\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "\n",
    "plt.grid(True, which=\"both\")\n",
    "plt.xlabel('Hidden weights bits')\n",
    "plt.ylabel('Test accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn = Path(f'fig/exp_add2_{dataset}.pdf')\n",
    "# fig.savefig(fn, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Out Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "our_all = pd.read_csv(f'out/{dataset}/our.csv')\n",
    "our_train_out_all = pd.read_csv(f'out/{dataset}/our_train_out.csv')\n",
    "\n",
    "layers = our_train_out_all['layers'].tolist()\n",
    "# Sort layers by number of parameters (product of dims)\n",
    "layers = sorted(layers, key=lambda x: np.prod([int(i) for i in x.split('_')]))\n",
    "\n",
    "# Collect validation accuracies for each layer config\n",
    "train_out_acc = [our_train_out_all[our_train_out_all['layers'] == l]['mean_val_acc'].values for l in layers]\n",
    "all_acc = [our_all[our_all['layers'] == l]['mean_val_acc'].values for l in layers]\n",
    "\n",
    "results = []\n",
    "for idx, layer in enumerate(layers):\n",
    "    mean_train = our_train_out_all.loc[our_train_out_all['layers'] == layer, 'mean_val_acc'].values[0]\n",
    "    std_train = our_train_out_all.loc[our_train_out_all['layers'] == layer, 'std_val_acc'].values[0]\n",
    "    mean_all = our_all.loc[our_all['layers'] == layer, 'mean_val_acc'].values[0]\n",
    "    std_all = our_all.loc[our_all['layers'] == layer, 'std_val_acc'].values[0]\n",
    "    results.append({\n",
    "        \"Layers\": layer,\n",
    "        \"Train-out\": f\"{mean_train:.2f} ± {std_train:.2f}\",\n",
    "        \"Fixed-out\": f\"{mean_all:.2f} ± {std_all:.2f}\"\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
